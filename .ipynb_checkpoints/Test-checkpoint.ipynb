{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442de828-1315-49d1-adc4-a6e399725b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & Global configuration \n",
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from requests import get\n",
    "from functools import wraps\n",
    "from collections import defaultdict\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CALENDAR_YMD = \"20240614\"\n",
    "LISTINGS_YMD = \"20250615\"\n",
    "CITY = \"London\"\n",
    "\n",
    "HOST = \"https://orca.casa.ucl.ac.uk\"\n",
    "ORCA_PATH = \"~jreades/data\"\n",
    "\n",
    "# ORCA filenames\n",
    "CALENDAR_FILE = RAW_DIR / f\"{CALENDAR_YMD}-{CITY}-calendar.csv.gz\"\n",
    "LISTINGS_FILE = RAW_DIR / f\"{LISTINGS_YMD}-{CITY}-listings.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b371241e-cd8b-4680-b902-d5a402274552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. cache helper\n",
    "def check_cache(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(src: str, dst_dir: Path, min_size: int = 100) -> Path:\n",
    "        src0 = src.split(\"?\")[0]\n",
    "        fn = Path(src0).name\n",
    "        dst = dst_dir / fn\n",
    "\n",
    "        if dst.is_file() and dst.stat().st_size > min_size:\n",
    "            print(f\"+ {dst} found locally!\")\n",
    "            return dst\n",
    "        else:\n",
    "            print(f\"+ {dst} not found, downloading!\")\n",
    "            return f(src, dst)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@check_cache\n",
    "def cache_data(src: str, dst: Path) -> Path:\n",
    "    if not dst.parent.exists():\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with dst.open(\"wb\") as f:\n",
    "        r = get(src)\n",
    "        r.raise_for_status()\n",
    "        f.write(r.content)\n",
    "\n",
    "    print(\"+ Done downloading.\")\n",
    "    return dst.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d7cdcf-6705-4cbb-9d8f-1b787f9e92ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ data/raw/20250615-London-listings.csv.gz found locally!\n",
      "+ data/raw/20240614-London-calendar.csv.gz found locally!\n"
     ]
    }
   ],
   "source": [
    "# 3. download/cache ORCA data\n",
    "listings_url = f\"{HOST}/{ORCA_PATH}/{LISTINGS_FILE.name}\"\n",
    "calendar_url = f\"{HOST}/{ORCA_PATH}/{CALENDAR_FILE.name}\"\n",
    "\n",
    "listings_path = cache_data(listings_url, RAW_DIR)\n",
    "calendar_path = cache_data(calendar_url, RAW_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d48085e-da7b-42bd-886b-611ee98e345e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listings: (96651, 79)\n"
     ]
    }
   ],
   "source": [
    "# 4. read listings\n",
    "listings = pd.read_csv(listings_path)\n",
    "\n",
    "print(\"Listings:\", listings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de9fd9f-f6df-4fda-85ed-16dac7dbd748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93480, 5)\n",
      "   listing_id  occupied_nights  total_nights  available_nights  occupancy_rate\n",
      "0       13913               34           364               330        0.093407\n",
      "1       15400              202           364               162        0.554945\n",
      "2       17402              100           363               263        0.275482\n",
      "3       24328              363           363                 0        1.000000\n",
      "4       33332                0           365               365        0.000000\n"
     ]
    }
   ],
   "source": [
    "# 5.read calendar by chunks\n",
    "CHUNK_SIZE  = 200_000\n",
    "\n",
    "def summarise_calendar_streaming(\n",
    "    path: Path,\n",
    "    chunk_size: int = CHUNK_SIZE,\n",
    "    start_date: str = \"2024-06-14\",\n",
    "    end_date: str   = \"2025-06-14\",\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    agg = {}  # {listing_id: [occupied_nights, total_nights]}\n",
    "\n",
    "    for chunk in pd.read_csv(\n",
    "        path,\n",
    "        chunksize=chunk_size,\n",
    "        usecols=[\"listing_id\", \"available\", \"date\"],\n",
    "        low_memory=False\n",
    "    ):\n",
    "\n",
    "        chunk[\"date\"] = pd.to_datetime(chunk[\"date\"], errors=\"coerce\")\n",
    "        chunk = chunk.dropna(subset=[\"date\"])\n",
    "\n",
    "        mask = (chunk[\"date\"] >= start_date) & (chunk[\"date\"] < end_date)\n",
    "        chunk = chunk.loc[mask]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "        chunk[\"is_occupied\"] = (\n",
    "            chunk[\"available\"].astype(str).str.lower() == \"f\"\n",
    "        )\n",
    "\n",
    "        grouped = (\n",
    "            chunk\n",
    "            .groupby(\"listing_id\")[\"is_occupied\"]\n",
    "            .agg([\"sum\", \"count\"])\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        for _, row in grouped.iterrows():\n",
    "            lid = int(row[\"listing_id\"])\n",
    "            occ = int(row[\"sum\"])\n",
    "            tot = int(row[\"count\"])\n",
    "\n",
    "            if lid not in agg:\n",
    "                agg[lid] = [0, 0]\n",
    "\n",
    "            agg[lid][0] += occ\n",
    "            agg[lid][1] += tot\n",
    "\n",
    "    summary = (\n",
    "        pd.DataFrame.from_dict(\n",
    "            agg,\n",
    "            orient=\"index\",\n",
    "            columns=[\"occupied_nights\", \"total_nights\"]\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"listing_id\"})\n",
    "    )\n",
    "\n",
    "    summary[\"available_nights\"] = (\n",
    "        summary[\"total_nights\"] - summary[\"occupied_nights\"]\n",
    "    )\n",
    "    summary[\"occupancy_rate\"] = (\n",
    "        summary[\"occupied_nights\"] / summary[\"total_nights\"]\n",
    "    )\n",
    "\n",
    "    return summary\n",
    "occ_summary = summarise_calendar_streaming(CALENDAR_FILE)\n",
    "print(occ_summary.shape)\n",
    "print(occ_summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f251d7-73ec-41ef-835c-b9f7b93c7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. thresholds / constants\n",
    "VIOLATION_THRESHOLD        = 90\n",
    "COMMERCIAL_AVAIL_THRESHOLD = 60\n",
    "HOTEL_LIKE_OCC_THRESHOLD   = 180\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"axes.titlesize\"] = 12\n",
    "plt.rcParams[\"axes.labelsize\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a18a7c-377e-47ab-b811-1aa59597e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Core wrangling helpers (used by Q1/Q2/Q3)\n",
    "def load_listings(path: Path) -> pd.DataFrame:\n",
    "    cols_in_file = pd.read_csv(path, nrows=0).columns.tolist()\n",
    "\n",
    "    desired_cols = [\n",
    "        \"id\", \"host_id\", \"room_type\",\n",
    "        \"neighbourhood_cleansed\", \"neighbourhood_group_cleansed\",\n",
    "        \"latitude\", \"longitude\",\n",
    "        \"number_of_reviews\", \"price\",\n",
    "    ]\n",
    "    usecols = [c for c in desired_cols if c in cols_in_file]\n",
    "\n",
    "    df = pd.read_csv(path, usecols=usecols, low_memory=False)\n",
    "\n",
    "    if \"price\" in df.columns:\n",
    "        price_str = df[\"price\"].astype(str).str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "        df[\"price_clean\"] = pd.to_numeric(price_str, errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"price_clean\"] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_calendar_listings(occ_summary: pd.DataFrame, listings: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols_to_keep = [\n",
    "        \"id\", \"host_id\", \"room_type\",\n",
    "        \"neighbourhood_cleansed\", \"neighbourhood_group_cleansed\",\n",
    "        \"latitude\", \"longitude\",\n",
    "        \"number_of_reviews\", \"price_clean\",\n",
    "    ]\n",
    "    existing_cols = [c for c in cols_to_keep if c in listings.columns]\n",
    "\n",
    "    merged = occ_summary.merge(\n",
    "        listings[existing_cols].drop_duplicates(subset=\"id\"),\n",
    "        left_on=\"listing_id\",\n",
    "        right_on=\"id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    return merged\n",
    "\n",
    "\n",
    "def add_core_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"is_entire_home\"] = df[\"room_type\"].eq(\"Entire home/apt\")\n",
    "\n",
    "    if not {\"occupied_nights\", \"available_nights\"}.issubset(df.columns):\n",
    "        raise ValueError(\"缺少 occupied_nights 或 available_nights 列。\")\n",
    "\n",
    "    df[\"violates_90day\"] = df[\"occupied_nights\"] > VIOLATION_THRESHOLD\n",
    "    df[\"commercial_STR\"] = df[\"available_nights\"] > COMMERCIAL_AVAIL_THRESHOLD\n",
    "    df[\"hotel_like\"]     = df[\"occupied_nights\"] > HOTEL_LIKE_OCC_THRESHOLD\n",
    "\n",
    "    df[\"legal_but_commercial\"] = (~df[\"violates_90day\"]) & df[\"commercial_STR\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_merged(\n",
    "    calendar_path: Path,\n",
    "    listings_path: Path,\n",
    "    start_date: str = \"2024-06-14\",\n",
    "    end_date: str   = \"2025-06-14\",\n",
    ") -> pd.DataFrame:\n",
    "    print(f\"=== Core Step: Summarising calendar {start_date} ~ {end_date} ===\")\n",
    "    occ_summary = summarise_calendar_streaming(\n",
    "        calendar_path,\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "    )\n",
    "    print(\"  Listings with calendar data:\", len(occ_summary))\n",
    "\n",
    "    print(\"=== Core Step: Loading listings and merging ===\")\n",
    "    listings = load_listings(listings_path)\n",
    "    merged = merge_calendar_listings(occ_summary, listings)\n",
    "    merged = add_core_flags(merged)\n",
    "\n",
    "    del occ_summary\n",
    "    del listings\n",
    "\n",
    "    print(\"  Total listings in merged:\", merged[\"listing_id\"].nunique())\n",
    "    print(\"  Columns:\", list(merged.columns))\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e09d58d4-3a2b-4264-90d2-c1f7874412e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Core Step: Summarising calendar 2024-06-14 ~ 2025-06-14 ===\n",
      "  Listings with calendar data: 93480\n",
      "=== Core Step: Loading listings and merging ===\n",
      "  Total listings in merged: 93480\n",
      "  Columns: ['listing_id', 'occupied_nights', 'total_nights', 'available_nights', 'occupancy_rate', 'id', 'host_id', 'room_type', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude', 'longitude', 'number_of_reviews', 'price_clean', 'is_entire_home', 'violates_90day', 'commercial_STR', 'hotel_like', 'legal_but_commercial']\n"
     ]
    }
   ],
   "source": [
    "# 8. read calendar&listings，merge, flag\n",
    "merged = prepare_merged(\n",
    "    calendar_path=calendar_path,\n",
    "    listings_path=listings_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7657a7e4-4f40-4665-8eb6-af5212d525a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged shape: (93480, 19)\n",
      "columns: ['listing_id', 'occupied_nights', 'total_nights', 'available_nights', 'occupancy_rate', 'id', 'host_id', 'room_type', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude', 'longitude', 'number_of_reviews', 'price_clean', 'is_entire_home', 'violates_90day', 'commercial_STR', 'hotel_like', 'legal_but_commercial'] ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'BOROUGH_COL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmerged shape:\u001b[39m\u001b[33m\"\u001b[39m, merged.shape)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mcolumns:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(merged.columns)[:\u001b[32m30\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m need_cols = [\u001b[33m\"\u001b[39m\u001b[33mlisting_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moccupied_nights\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mavailable_nights\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mroom_type\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m              \u001b[33m\"\u001b[39m\u001b[33mis_entire_home\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mviolates_90day\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcommercial_STR\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mBOROUGH_COL\u001b[49m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m need_cols:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mOK\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m merged.columns \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMISSING\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'BOROUGH_COL' is not defined"
     ]
    }
   ],
   "source": [
    "# 9. \n",
    "print(\"merged shape:\", merged.shape)\n",
    "print(\"columns:\", list(merged.columns)[:30], \"...\")\n",
    "\n",
    "need_cols = [\"listing_id\", \"occupied_nights\", \"available_nights\", \"room_type\",\n",
    "             \"is_entire_home\", \"violates_90day\", \"commercial_STR\", BOROUGH_COL]\n",
    "for c in need_cols:\n",
    "    print(f\"{c}: \", \"OK\" if c in merged.columns else \"MISSING\")\n",
    "\n",
    "if \"room_type\" in merged.columns:\n",
    "    print(\"\\nroom_type value counts (top 10):\")\n",
    "    print(merged[\"room_type\"].value_counts(dropna=False).head(10))\n",
    "\n",
    "if \"is_entire_home\" in merged.columns:\n",
    "    print(\"\\nis_entire_home counts:\")\n",
    "    print(merged[\"is_entire_home\"].value_counts(dropna=False))\n",
    "\n",
    "if BOROUGH_COL in merged.columns:\n",
    "    print(f\"\\n{BOROUGH_COL} missing rate:\", merged[BOROUGH_COL].isna().mean())\n",
    "    print(f\"{BOROUGH_COL} top 10:\")\n",
    "    print(merged[BOROUGH_COL].value_counts(dropna=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d75b3b-b1e0-4c76-b6eb-22ba131b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.Policy\n",
    "\n",
    "# entire-home\n",
    "def _unique_entire_listings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df[df[\"is_entire_home\"]].copy()\n",
    "    out = out.drop_duplicates(subset=\"listing_id\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def citywide_violation_stats(df: pd.DataFrame) -> dict:\n",
    "    entire = _unique_entire_listings(df)\n",
    "    total_entire = entire[\"listing_id\"].nunique()\n",
    "\n",
    "    n_viol = int(entire[\"violates_90day\"].sum())\n",
    "    share_viol = n_viol / total_entire if total_entire > 0 else np.nan\n",
    "\n",
    "    n_comm = int(entire[\"commercial_STR\"].sum())\n",
    "    share_comm = n_comm / total_entire if total_entire > 0 else np.nan\n",
    "\n",
    "    overlap = int((entire[\"violates_90day\"] & entire[\"commercial_STR\"]).sum())\n",
    "    overlap_rate = overlap / n_viol if n_viol > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"total_entire_homes\": int(total_entire),\n",
    "        \"n_violates_90day\": int(n_viol),\n",
    "        \"share_violates_90day\": share_viol,\n",
    "        \"n_commercial_entire\": int(n_comm),\n",
    "        \"share_commercial_entire\": share_comm,\n",
    "        \"overlap_count\": int(overlap),\n",
    "        \"overlap_rate_within_violations\": overlap_rate,\n",
    "    }\n",
    "\n",
    "def neighbourhood_violation_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    entire = _unique_entire_listings(df)\n",
    "    entire = entire.dropna(subset=[BOROUGH_COL]).copy()\n",
    "\n",
    "    grouped = (\n",
    "        entire\n",
    "        .groupby(BOROUGH_COL)\n",
    "        .agg(\n",
    "            n_entire=(\"listing_id\", \"nunique\"),\n",
    "            n_violations=(\"violates_90day\", \"sum\"),\n",
    "            n_commercial=(\"commercial_STR\", \"sum\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={BOROUGH_COL: \"borough\"})\n",
    "    )\n",
    "\n",
    "    grouped[\"share_violations\"] = grouped[\"n_violations\"] / grouped[\"n_entire\"]\n",
    "    grouped[\"share_commercial\"] = grouped[\"n_commercial\"] / grouped[\"n_entire\"]\n",
    "\n",
    "    return grouped\n",
    "\n",
    "# Figure 1 \n",
    "def plot_occupied_histogram(df: pd.DataFrame) -> None:\n",
    "    entire = _unique_entire_listings(df)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(entire[\"occupied_nights\"].dropna(), bins=30)\n",
    "    plt.axvline(\n",
    "        VIOLATION_THRESHOLD,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"90-night limit\"\n",
    "    )\n",
    "    plt.xlabel(\"Occupied nights (entire homes)\")\n",
    "    plt.ylabel(\"Number of listings\")\n",
    "    plt.title(\"Distribution of occupied nights (entire homes)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Figure 2\n",
    "def plot_top_violation_areas(neigh_stats: pd.DataFrame, top_n: int = 20) -> None:\n",
    "    df = neigh_stats.sort_values(\"share_violations\", ascending=False).head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(df[\"borough\"], df[\"share_violations\"])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Share of entire homes violating 90-day rule\")\n",
    "    plt.ylabel(\"Borough\")\n",
    "    plt.title(f\"Top {top_n} boroughs by 90-day rule violation rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Figure 3 \n",
    "def plot_share_commercial_vs_violations(neigh_stats: pd.DataFrame) -> None:\n",
    "    df = neigh_stats.dropna(subset=[\"share_violations\", \"share_commercial\"]).copy()\n",
    "    if df.empty:\n",
    "        print(\"No borough data，skip offset points.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.scatter(df[\"share_violations\"], df[\"share_commercial\"])\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        plt.annotate(\n",
    "            row[\"borough\"],\n",
    "            (row[\"share_violations\"], row[\"share_commercial\"]),\n",
    "            fontsize=8,\n",
    "            xytext=(3, 3),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Share of 90-day violations (entire homes)\")\n",
    "    plt.ylabel(\"Share of commercial STR (entire homes)\")\n",
    "    plt.title(\"Commercial STR vs 90-day violations by borough\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_policy_from_merged(merged: pd.DataFrame) -> dict:\n",
    "    print(\"=== Policy: city-level stats ===\")\n",
    "    city_stats = citywide_violation_stats(merged)\n",
    "    for k, v in city_stats.items():\n",
    "        if isinstance(v, float):\n",
    "            if \"share\" in k or \"rate\" in k:\n",
    "                print(f\"  {k}: {v:.2%}\")\n",
    "            else:\n",
    "                print(f\"  {k}: {v:.2f}\")\n",
    "        else:\n",
    "            print(f\"  {k}: {v}\")\n",
    "\n",
    "    print(\"\\n=== Policy: borough-level stats ===\")\n",
    "    neigh_stats = neighbourhood_violation_stats(merged)\n",
    "    print(neigh_stats.head())\n",
    "\n",
    "    print(\"\\n=== Figure 1 ===\")\n",
    "    plot_occupied_histogram(merged)\n",
    "\n",
    "    print(\"\\n=== Figure 2 ===\")\n",
    "    plot_top_violation_areas(neigh_stats, top_n=20)\n",
    "\n",
    "    print(\"\\n=== Figure 3 ===\")\n",
    "    plot_share_commercial_vs_violations(neigh_stats)\n",
    "\n",
    "    print(\"\\n=== Policy analysis done. ===\")\n",
    "    return {\n",
    "        \"city_stats\": city_stats,\n",
    "        \"borough_stats\": neigh_stats\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0399aced-a699-4208-a511-19efc2a5cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 Policy Result \n",
    "results_policy = run_policy_from_merged(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16cc53-98a6-447e-975e-890a7008bdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19019344-d0e7-4e09-a592-b46ecaacc3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613068c-51fd-40bd-b52e-3597fe0dcc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. group-provided borough data (local)\n",
    "\n",
    "TABLE_DIR = DATA_DIR / \"table\"\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RENT_EXCEL_PATH =TABLE_DIR / \"borough_rent_2024_07_2025_06.xlsx\"\n",
    "\n",
    "if not RENT_EXCEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing file: {RENT_EXCEL_PATH.resolve()}\")\n",
    "\n",
    "rent  = pd.read_excel(RENT_EXCEL_PATH)\n",
    "\n",
    "print(\"Rent:\", rent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d80d79-55d6-4d14-a306-673839691a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 Commercial\n",
    "def _unique_listings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"listing_id\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame 缺少 listing_id 列。\")\n",
    "    return df.drop_duplicates(subset=\"listing_id\").copy()\n",
    "\n",
    "\n",
    "def compute_entire_home_stats(df: pd.DataFrame) -> dict:\n",
    "    d = _unique_listings(df)\n",
    "\n",
    "    total_listings = d[\"listing_id\"].nunique()\n",
    "    entire = d[d[\"is_entire_home\"]]\n",
    "    n_entire = entire[\"listing_id\"].nunique()\n",
    "    share_entire = n_entire / total_listings if total_listings > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"total_listings\": int(total_listings),\n",
    "        \"n_entire\": int(n_entire),\n",
    "        \"share_entire\": share_entire,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_host_structure(df: pd.DataFrame) -> dict:\n",
    "    d = _unique_listings(df)\n",
    "\n",
    "    d = d.dropna(subset=[\"host_id\"]).copy()\n",
    "\n",
    "    host_counts = d.groupby(\"host_id\")[\"listing_id\"].nunique()\n",
    "    total_hosts = int(host_counts.size)\n",
    "    total_listings = int(d[\"listing_id\"].nunique())\n",
    "\n",
    "    n_multi_hosts = int((host_counts >= 2).sum())\n",
    "    listing_by_multi = int(host_counts[host_counts >= 2].sum())\n",
    "\n",
    "    stats = {\n",
    "        \"host_counts\": host_counts,\n",
    "        \"total_hosts\": total_hosts,\n",
    "        \"total_listings\": total_listings,\n",
    "        \"n_multi_hosts\": n_multi_hosts,\n",
    "        \"share_multi_hosts\": (n_multi_hosts / total_hosts) if total_hosts > 0 else np.nan,\n",
    "        \"listing_by_multi\": listing_by_multi,\n",
    "        \"share_listing_by_multi\": (listing_by_multi / total_listings) if total_listings > 0 else np.nan,\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "\n",
    "def compute_availability_stats(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Availability-based STR categories (entire homes only):\n",
    "      - commercial_STR / hotel_like / legal_but_commercial 这些 flag 已经在 merged 里打好\n",
    "    \"\"\"\n",
    "    d = _unique_listings(df)\n",
    "    entire = d[d[\"is_entire_home\"]].copy()\n",
    "    n_entire = int(entire[\"listing_id\"].nunique())\n",
    "\n",
    "    n_commercial = int(entire[\"commercial_STR\"].sum())\n",
    "    share_commercial = n_commercial / n_entire if n_entire > 0 else np.nan\n",
    "\n",
    "    n_hotel_like = int(entire[\"hotel_like\"].sum())\n",
    "    share_hotel_like = n_hotel_like / n_entire if n_entire > 0 else np.nan\n",
    "\n",
    "    n_legal_but_commercial = int(entire[\"legal_but_commercial\"].sum())\n",
    "    share_legal_but_comm = n_legal_but_commercial / n_entire if n_entire > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"n_entire\": n_entire,\n",
    "        \"n_commercial_entire\": n_commercial,\n",
    "        \"share_commercial_entire\": share_commercial,\n",
    "        \"n_hotel_like_entire\": n_hotel_like,\n",
    "        \"share_hotel_like_entire\": share_hotel_like,\n",
    "        \"n_legal_but_commercial_entire\": n_legal_but_commercial,\n",
    "        \"share_legal_but_commercial_entire\": share_legal_but_comm,\n",
    "    }\n",
    "\n",
    "\n",
    "#Figure 4.\n",
    "def plot_host_distribution(host_structure_stats: dict, max_listings: int = 12) -> None:\n",
    "    host_counts: pd.Series = host_structure_stats[\"host_counts\"]\n",
    "    vc = host_counts.value_counts().sort_index()\n",
    "\n",
    "    vc_main = vc[vc.index <= max_listings].copy()\n",
    "    others = int(vc[vc.index > max_listings].sum())\n",
    "\n",
    "    if others > 0:\n",
    "        vc_main.loc[max_listings + 1] = others\n",
    "        labels = [str(i) for i in range(1, max_listings + 1)] + [f\"{max_listings+1}+\"]\n",
    "        vc_main.index = labels\n",
    "    else:\n",
    "        vc_main.index = [str(i) for i in vc_main.index]\n",
    "\n",
    "    plt.figure()\n",
    "    vc_main.plot(kind=\"bar\")\n",
    "    plt.xlabel(\"Number of listings per host\")\n",
    "    plt.ylabel(\"Number of hosts\")\n",
    "    plt.title(\"Host size distribution (market structure)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Figure 5.\n",
    "def plot_commercial_shares(avail_stats: dict) -> None:\n",
    "    labels = [\n",
    "        \"Commercial STR (entire)\",\n",
    "        \"Hotel-like STR (entire)\",\n",
    "        \"Legal but commercial (entire)\",\n",
    "    ]\n",
    "    values = [\n",
    "        avail_stats[\"share_commercial_entire\"],\n",
    "        avail_stats[\"share_hotel_like_entire\"],\n",
    "        avail_stats[\"share_legal_but_commercial_entire\"],\n",
    "    ]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(labels, values)\n",
    "    plt.ylabel(\"Share of entire homes\")\n",
    "    plt.title(\"Availability-based STR categories\")\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_commercial_from_merged(merged: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Commercial analysis (restricted):\n",
    "      - Entire-home share (printed)\n",
    "      - Host structure (printed)\n",
    "      - Availability-based categories (printed)\n",
    "      - Figures:\n",
    "          C1 Host size distribution\n",
    "          C2 Availability-based STR categories\n",
    "    \"\"\"\n",
    "    print(\"=== Commercial: Entire-home share ===\")\n",
    "    entire_stats = compute_entire_home_stats(merged)\n",
    "    print(entire_stats)\n",
    "\n",
    "    print(\"\\n=== Commercial: Host structure ===\")\n",
    "    host_stats = compute_host_structure(merged)\n",
    "    print(\"Total hosts:\", host_stats[\"total_hosts\"])\n",
    "    print(\"Multi-host share:\", host_stats[\"share_multi_hosts\"])\n",
    "    print(\"Listings controlled by multi-hosts:\", host_stats[\"share_listing_by_multi\"])\n",
    "\n",
    "    print(\"\\n=== Commercial: Availability-based STR categories ===\")\n",
    "    avail_stats = compute_availability_stats(merged)\n",
    "    for k, v in avail_stats.items():\n",
    "        if k.startswith(\"share_\"):\n",
    "            print(f\"{k}: {v:.2%}\")\n",
    "        else:\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"\\n=== Figure C1: Host size distribution ===\")\n",
    "    plot_host_distribution(host_stats, max_listings=12)\n",
    "\n",
    "    print(\"\\n=== Figure C2: Availability-based STR categories ===\")\n",
    "    plot_commercial_shares(avail_stats)\n",
    "\n",
    "    print(\"\\n=== Commercial analysis done . ===\")\n",
    "    return {\n",
    "        \"entire_stats\": entire_stats,\n",
    "        \"host_stats\": host_stats,\n",
    "        \"avail_stats\": avail_stats,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f2e2f-5dfe-4730-8aa6-1e06ba1c6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 Commercial Result \n",
    "results_commercial = run_commercial_from_merged(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5462fbf-b0ed-4802-8691-ee2ec6ec02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 Spatial Read \n",
    "GEO_DIR = DATA_DIR / \"geo\"\n",
    "GEO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/src/Boroughs.gpkg\"\n",
    "out = GEO_DIR / \"Boroughs.gpkg\"\n",
    "\n",
    "if not out.exists() or out.stat().st_size < 1000:\n",
    "    print(\"Downloading Boroughs.gpkg ...\")\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    out.write_bytes(r.content)\n",
    "else:\n",
    "    print(\"Boroughs.gpkg already exists\")\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf30d2-f2fe-4524-9198-ebb89041abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "boros = gpd.read_file(\"data/geo/Boroughs.gpkg\")\n",
    "boros[\"borough\"] = boros[\"NAME\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "pts = gpd.GeoDataFrame(\n",
    "    merged.copy(),\n",
    "    geometry=gpd.points_from_xy(merged[\"longitude\"], merged[\"latitude\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "pts = pts.to_crs(boros.crs)\n",
    "\n",
    "pts_boro = gpd.sjoin(\n",
    "    pts,\n",
    "    boros[[\"borough\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"  \n",
    ")\n",
    "\n",
    "pts_boro[\"borough\"].isna().mean()\n",
    "pts_boro[[\"listing_id\",\"borough\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb0207-5a3d-43c2-92f9-4b0787820eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16 Stock Read\n",
    "STOCK_CSV_PATH =TABLE_DIR /\"social-landlord-housing-stock-borough.csv\"\n",
    "\n",
    "if not STOCK_CSV_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing file:{STOCK_CSV_PATH.resolve()}\")\n",
    "\n",
    "stock = pd.read_csv(STOCK_CSV_PATH)\n",
    "\n",
    "print(\"Stock:\", stock.shape)\n",
    "stock.head()\n",
    "stock.columns\n",
    "stock.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a3517-b1c2-4e00-9a57-96505beb29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17 Stock \n",
    "stock2 = stock.copy()\n",
    "stock2[\"borough\"] = stock2[\"Area\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "dwell_col = \"Number of self-contained units or bedspaces-2024\"\n",
    "print(\"Using dwellings column:\", dwell_col)\n",
    "\n",
    "housing = stock2[[\"borough\", dwell_col]].rename(\n",
    "    columns={dwell_col: \"dwellings\"}\n",
    ").copy()\n",
    "\n",
    "housing[\"dwellings\"] = (\n",
    "    housing[\"dwellings\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "housing[\"dwellings\"] = pd.to_numeric(\n",
    "    housing[\"dwellings\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "housing.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
