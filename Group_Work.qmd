---
date: last-modified
bibliography: references.bib
csl: harvard-cite-them-right.csl
title: FIVE GUYS' Group Project
execute:
  echo: false
  freeze: true
format:
  html:
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
        \usepackage{fvextra}
        \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,breakanywhere,commandchars=\\\{\}}
        \fvset{breaklines=true,breakanywhere=true}
    mainfont: Spectral
    sansfont: "Roboto Flex"
    monofont: "Liberation Mono"
    papersize: a4
    geometry:
      - top=25mm
      - left=30mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

## Declaration of Authorship {.unnumbered .unlisted}

We, FIVE GUYS, pledge our honour that the work presented in this assessment is our own. Where information has been derived from other sources, we confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used we confirm that we have made its contribution to the final submission clear.

Date:21/11/2025

Student Numbers: 22199699; 25135657; 25148717; 25049635; 25111746.

## Priorities for Feedback

We would appreciate feedback on the methodological choices made in defining professional landlords and on the effectiveness of our data processing and spatial analysis workflow.

{{< pagebreak >}}

# Q1. Is Airbnb “out of control” in London?

### Policy

London’s 90-day rule is the key legal benchmark for assessing whether Airbnb is “out of control [@Rozena07022023; @doi:10.1177/0042098020970865].” Under the Deregulation Act 2015, a dwelling may be short-let for up to 90 nights per calendar year without planning permission; exceeding this threshold constitutes a material change of use and is therefore unlawful[@doi:10.1177/0042098020970865]. Short-term rentals (STRs) refer to residential properties offered for temporary accommodation, typically for periods of less than one month, through platforms such as Airbnb. The rule aims to prevent the commercialisation of entire homes and protect long-term housing supply. Using the calendar and listings datasets in Jupyter, we calculated occupied_nights for entire homes to assess compliance. For the Mayor, these patterns matter because they indicate that existing safeguards are failing to distinguish between casual home-sharing and large-scale commercial use—exposing the administration to claims of weak oversight.

Three patterns suggest significant weaknesses in the current regulatory framework.

```{python}
#| echo: false
#1 Imports & Paths & Constants
import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import requests
import warnings
import os

from pathlib import Path
from functools import wraps
from libpysal.weights import Queen

## 1.1 Project directories
DATA_DIR = Path("data")
RAW_DIR  = DATA_DIR / "raw"
GEO_DIR  = DATA_DIR / "geo"
TABLE_DIR = DATA_DIR / "table"

for d in [DATA_DIR, RAW_DIR, GEO_DIR, TABLE_DIR]:
    d.mkdir(parents=True, exist_ok=True)

## 1.2 Data source configuration (ORCA)
CITY = "London"

CALENDAR_YMD = "20240614"
LISTINGS_YMD = "20250615"

HOST = "https://orca.casa.ucl.ac.uk"
ORCA_PATH = "~jreades/data"

CALENDAR_FILE = f"{CALENDAR_YMD}-{CITY}-calendar.csv.gz"
LISTINGS_FILE = f"{LISTINGS_YMD}-{CITY}-listings.csv.gz"

## 1.3 Policy thresholds
VIOLATION_THRESHOLD = 90          # London 90-day rule
COMMERCIAL_AVAIL_THRESHOLD = 60   # proxy for commercial STR
HOTEL_LIKE_OCC_THRESHOLD = 180    # hotel-like behaviour

## 1.4 Plot defaults
plt.rcParams.update({
    "figure.figsize": (8, 5),
    "axes.titlesize": 12,
    "axes.labelsize": 10,
})

## 1.5 Utility helpers
def vprint(verbose: bool, *args, **kwargs) -> None:
    if verbose:
        print(*args, **kwargs)
```

```{python}
#| echo: false
#2 Data Download & Caching 
## 2.1 Cache
def check_cache(f):
    """Download file only if it does not already exist locally."""
    @wraps(f)
    def wrapper(src: str,dst_dir: Path,min_size: int = 1000,verbose: bool = False) -> Path:
        filename = Path(src.split("?")[0]).name
        dst = dst_dir / filename
        if dst.exists() and dst.stat().st_size > min_size:
            if verbose:
                print(f"Using cached file: {dst.name}")
            return dst
        if verbose:
            print(f"Downloading: {dst.name}")
        return f(src, dst)
    return wrapper

@check_cache
def cache_data(src: str, dst: Path) -> Path:
    dst.parent.mkdir(parents=True, exist_ok=True)
    response = requests.get(src)
    response.raise_for_status()
    dst.write_bytes(response.content)
    return dst.resolve()

## 2.2 Download ORCA Listing & Calendar
listings_url = f"{HOST}/{ORCA_PATH}/{LISTINGS_FILE}"
calendar_url = f"{HOST}/{ORCA_PATH}/{CALENDAR_FILE}"

listings_path = cache_data(listings_url, RAW_DIR)
calendar_path = cache_data(calendar_url, RAW_DIR)

## 2.3 Download Borough Polygons (gpkg)
borough_url = (
    "https://raw.githubusercontent.com/jreades/fsds/"
    "master/data/src/Boroughs.gpkg"
)
borough_path = cache_data(borough_url, GEO_DIR)

STOCK_URL = (
    "https://raw.githubusercontent.com/XINRUIQI/fsds-group/"
    "main/data/table/social-landlord-housing-stock-borough.csv"
)
stock_path = cache_data(STOCK_URL, TABLE_DIR)
```


```{python}
#| echo: false
#3 Core Wrangling: read listings & stream calendar & merge & flags
SHOW_TABLES = False
CHUNK_SIZE = 200_000

def load_listings(path: Path) -> pd.DataFrame:
    """Read a minimal set of listing attributes."""
    cols_in_file = pd.read_csv(path, nrows=0).columns.tolist()

    desired = [ "id", "host_id", "room_type",
                "neighbourhood_cleansed", 
                "neighbourhood_group_cleansed", 
                "latitude", "longitude", 
                "number_of_reviews", "price",]
    usecols = [c for c in desired if c in cols_in_file]
    df = pd.read_csv(path, usecols=usecols, low_memory=False)

    # clean price if present
    if "price" in df.columns:
        price_str = (df["price"].astype(str).str.replace(r"[^\d.]", "", regex=True))
        df["price_clean"] = pd.to_numeric(price_str, errors="coerce")
    return df

def summarise_calendar_streaming(
    path: Path,
    chunk_size: int = CHUNK_SIZE,
    start_date: str = "2024-06-14",
    end_date: str   = "2025-06-14",
    verbose: bool = False,
) -> pd.DataFrame:
    """Stream calendar.csv.gz""" 
    """aggregate occupied/total nights per listing."""
    agg = {}  # {listing_id: [occupied_nights, total_nights]}
    if verbose:
        print("Streaming calendar file...")

    for chunk in pd.read_csv(
        path,
        chunksize=chunk_size,
        usecols=["listing_id", "available", "date"],
        low_memory=False
    ):
        chunk["date"] = pd.to_datetime(chunk["date"], errors="coerce")
        chunk = chunk.dropna(subset=["date"])
        mask = (chunk["date"] >= start_date) & (chunk["date"] < end_date)
        chunk = chunk.loc[mask].copy()
        if chunk.empty:
            continue

        # normalise availability flag
        av = chunk["available"].astype(str).str.lower()
        chunk["is_available"] = av.isin(["t", "true", "1", "yes"])

        for lid, g in chunk.groupby("listing_id"):
            total = len(g)
            occ = int((~g["is_available"]).sum())  # occupied nights
            if lid not in agg:
                agg[lid] = [0, 0]
            agg[lid][0] += occ
            agg[lid][1] += total

    if verbose:
        print(f"Aggregated {len(agg):,} listings")


    summary = (
        pd.DataFrame.from_dict(agg,orient="index",columns=["occupied_nights", "total_nights"])
        .reset_index()
        .rename(columns={"index": "listing_id"})
    )

    summary["available_nights"] = (summary["total_nights"] - summary["occupied_nights"])
    summary["occupancy_rate"] = (summary["occupied_nights"] / summary["total_nights"])
    return summary

def merge_calendar_listings(occ_summary: pd.DataFrame,listings: pd.DataFrame) -> pd.DataFrame:
    cols_to_keep = [
        "id", "host_id", "room_type",
        "neighbourhood_cleansed", "neighbourhood_group_cleansed",
        "latitude", "longitude",
        "number_of_reviews", "price_clean",
    ]
    keep = [c for c in cols_to_keep if c in listings.columns]

    return occ_summary.merge(
        listings[keep].drop_duplicates(subset="id"),
        left_on="listing_id",
        right_on="id",
        how="left",
    )

def add_core_flags(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()

    # entire home flag
    room = out.get("room_type")
    out["is_entire_home"] = (
        room.astype(str).str.contains("entire", case=False, na=False)
        if room is not None else False
    )

    # 90-day rule violation (entire homes only)
    out["violates_90day"] = (
        out["is_entire_home"]
        & (out["occupied_nights"] > VIOLATION_THRESHOLD)
    )

    # commercial STR (your logic: available nights > threshold)
    out["commercial_STR"] = (
        out["is_entire_home"]
        & (out["available_nights"] > COMMERCIAL_AVAIL_THRESHOLD)
    )

    # hotel-like (your logic: occupied nights > threshold)
    out["hotel_like_STR"] = (
        out["is_entire_home"]
        & (out["occupied_nights"] > HOTEL_LIKE_OCC_THRESHOLD)
    )

    return out

def prepare_merged(calendar_path: Path,listings_path: Path,verbose: bool = False) -> pd.DataFrame:
    if verbose:
        print("=== Calendar → occupancy summary ===")

    occ_summary = summarise_calendar_streaming(calendar_path,verbose=verbose)
    if verbose:
        print("calendar summary:", occ_summary.shape)
        print("=== Listings → attributes ===")


    listings = load_listings(listings_path)
    if verbose:
        print("listings:", listings.shape)
        print("=== Merge + policy flags ===")

    merged = merge_calendar_listings(occ_summary, listings)
    merged = add_core_flags(merged)
    if verbose:
        print("merged:", merged.shape)
    
    return merged

merged = prepare_merged(calendar_path=calendar_path,listings_path=listings_path)

if SHOW_TABLES:
    merged.sample(5, random_state=42)
```

```{python}
#| echo: false
#4 Q1.1 Policy (90-day rule)
## 4.1 Function Definitions
def _entire_home_listings(df: pd.DataFrame) -> pd.DataFrame:
    """
    Return one row per listing, restricted to entire-home listings.
    Assumes a unique listing_id identifies a listing across calendar rows.
    """
    if "is_entire_home" not in df.columns:
        raise KeyError("Missing column: is_entire_home (run add_core_flags first).")

    return (df.loc[df["is_entire_home"]].drop_duplicates(subset="listing_id").copy())

def citywide_violation_stats(df: pd.DataFrame, verbose: bool = False) -> dict:
    """Citywide summary of 90-day rule violations among entire homes."""
    entire = _entire_home_listings(df)
    total_entire = int(entire["listing_id"].nunique())

    n_viol = int(entire["violates_90day"].sum()) if "violates_90day" in entire.columns else 0
    share_viol = (n_viol / total_entire) if total_entire > 0 else np.nan

    out = { "total_entire_homes": total_entire,
        "n_violations": n_viol,
        "share_violations": share_viol,
    }
    vprint(verbose, "Citywide stats:", out)
    return out

def violation_by_borough(df: pd.DataFrame,borough_col: str = "neighbourhood_cleansed",) -> pd.DataFrame:
    """Borough-level 90-day violation counts and shares (entire homes only)."""
    entire = _entire_home_listings(df).dropna(subset=[borough_col]).copy()

    out = (
        entire.groupby(borough_col, as_index=False)
              .agg(
                  n_entire=("listing_id", "nunique"),
                  n_violations=("violates_90day", "sum"),
              )
    )
    out["share_violations"] = out["n_violations"] / out["n_entire"]
    out = out.rename(columns={borough_col: "borough"})
    return out

def commercial_by_borough(df: pd.DataFrame,borough_col: str = "neighbourhood_cleansed",) -> pd.DataFrame:
    """Borough-level commercial STR counts and shares (entire homes only)."""
    entire = _entire_home_listings(df).dropna(subset=[borough_col]).copy()

    out = (
        entire.groupby(borough_col, as_index=False)
              .agg(
                  n_entire=("listing_id", "nunique"),
                  n_commercial=("commercial_STR", "sum"),
              )
    )
    out["commercial_share"] = out["n_commercial"] / out["n_entire"]
    out = out.rename(columns={borough_col: "borough"})
    return out

def build_borough_policy_table(df: pd.DataFrame) -> pd.DataFrame:
    """
    Borough-level table used in the policy section:
      - share_violations (90-day rule)
      - commercial_share (commercial STR)
    """
    policy = violation_by_borough(df)
    comm = commercial_by_borough(df)

    out = (
        policy.merge(comm[["borough", "commercial_share"]], on="borough", how="inner")
              .dropna(subset=["share_violations", "commercial_share"])
    )
    return out

## 4.2 Plots
def plot_occupied_nights_hist(df: pd.DataFrame) -> None:
    """Figure 1: Distribution of occupied nights for entire-home listings."""
    entire = _entire_home_listings(df)
    x = entire["occupied_nights"].dropna()

    plt.figure()
    plt.hist(x, bins=50)
    plt.axvline(VIOLATION_THRESHOLD, linestyle="--")
    plt.xlabel("Occupied nights (entire homes)")
    plt.ylabel("Number of listings")
    plt.title("Figure-1 Distribution of Occupied Nights (Entire Homes)")
    plt.tight_layout()

def plot_violation_areas(neigh_stats: pd.DataFrame) -> None:
    """Figure 2: Boroughs by 90-day violation share (all boroughs)."""
    df = neigh_stats.sort_values("share_violations", ascending=False)

    plt.figure(figsize=(10, 6))  
    plt.barh(df["borough"], df["share_violations"])
    plt.gca().invert_yaxis()
    plt.xlabel("Share of entire homes violating 90-day rule")
    plt.title("Figure-2 Boroughs by 90-day Violation Share")
    plt.tight_layout()

def plot_share_commercial_vs_violations(neigh_stats: pd.DataFrame) -> None:
    df = neigh_stats.dropna(subset=["share_violations", "commercial_share", "borough"]).copy()
    if df.empty:
        print("No valid boroughs for Figure 3, skipping plot.")
        return

    """Figure 3: Commercial STR share vs 90-day violation share by borough."""
    df["borough_label"] = df["borough"].astype(str).str.strip().str.title()

    plt.figure(figsize=(10, 6))

    plt.scatter(df["share_violations"], df["commercial_share"], s=60, alpha=0.8)
    
    dx, dy = 0.002, 0.002
    for _, r in df.iterrows():
        plt.text(
            r["share_violations"] + dx,
            r["commercial_share"] + dy,
            r["borough_label"],
            fontsize=9
        )
    plt.xlabel("Share of 90-day violations (entire homes)")
    plt.ylabel("Share of commercial STR (entire homes)")
    plt.title("Figure-3 Commercial STR vs 90-day Violations by Borough")
    plt.tight_layout()
```


```{python}
#| echo: false
## 4.3 Citywide 90-day rule stats + Figure 1 (toggleable)
RUN_CITYWIDE = True
SHOW_CITY_STATS = False
SHOW_CITY_PLOT  = True

if RUN_CITYWIDE:
    city = citywide_violation_stats(merged)

    if SHOW_CITY_STATS:
        print("=== Citywide 90-day rule stats ===")
        print(city)

    # Figure 1
    if SHOW_CITY_PLOT:
        plot_occupied_nights_hist(merged)
```
Figure 1 – Occupied nights: Many entire homes exceed the 90-night legal limit, showing widespread violation.(Occupied nights are inferred from availability data and may therefore represent an upper bound of potential non-compliance.)
```{python}
#| output: asis
entire = _entire_home_listings(merged)
print(
    f"Across all entire-home listings, approximately {entire['violates_90day'].mean():.0%} exceed the 90-night legal threshold."
)
```



```{python}
#| echo: false
## 4.4 Neighbourhood (borough) table + Figure 2 (toggleable)
RUN_NEIGH = True           
SHOW_NEIGH_TABLE = False 
SHOW_NEIGH_PLOT  = True   

if RUN_NEIGH:
    neigh = violation_by_borough(merged)
    if SHOW_NEIGH_TABLE:
        print("\n=== Neighbourhood (borough) violation table (all boroughs, sorted) ===")
        print(
            neigh
            .sort_values("share_violations", ascending=False)
            .round(3)
        )
    # Figure 2
    if SHOW_NEIGH_PLOT:
        plot_violation_areas(neigh)
```
Figure 2 – Borough violation rates: Most boroughs across Greater London record 70–90% non-compliance, indicating persistent enforcement challenges.
```{python}
#| output: asis
print(
    f"{(neigh['share_violations'] >= 0.7).sum()} out of {neigh.shape[0]} boroughs record violation rates above 70%."
)
```


```{python}
#| echo: false
# 4.5 Policy Figure 3: Commercial STR vs 90-day violations (toggleable)
RUN_FIG3 = True
SHOW_FIG3_STATS = False
SHOW_FIG3_PLOT = True

if RUN_FIG3:
    neigh_stats = build_borough_policy_table(merged)

    if SHOW_FIG3_STATS:
        print("\n=== Commercial STR vs 90-day violations ===")
        print(neigh_stats.head())

    if SHOW_FIG3_PLOT:
        plot_share_commercial_vs_violations(neigh_stats)
```
Figure 3 – Commercial STR correlation:Boroughs with high levels of non-compliance also exhibit substantial variation in the share of commercial STRs, indicating that widespread 90-day violations are not limited to areas dominated by clearly commercial operators. 

Together, these findings show that the 90-day rule is routinely breached in practice, and that London’s Airbnb market has expanded beyond effective regulatory control.

### Commercialisation

In this study, “commercial STRs” refer to short-term rental activity characterised by sustained, high-intensity use and investment-oriented operation, rather than occasional or supplementary home-sharing. A second way to assess whether Airbnb is “out of control” is to examine the commercialisation of London’s STR market[@ferreri2018platform; @Rozena07022023]. Prior research links investment-driven, multi-property STR operation to housing withdrawal and increased local housing pressure[@wachsmuth2018rentgap; @bivens2019airbnb]. 

Using the listings and calendar datasets in Jupyter, we detect commercialisation through host scale and availability intensity.

Listings were classified as "commercial" or "hotel-like"based on sustained year-round availability patterns indicative of continuous short-term letting rather than occasional use.“Hotel-like” STRs are understood here as listings operated in a manner analogous to hotels, with continuous availability and frequent guest turnover.

```{python}
#| echo: false
#5 Q1.2 Commercialisation
## 5.1 Function Definitions
def _unique_listings(df: pd.DataFrame) -> pd.DataFrame:
    """Return one row per listing."""
    return df.drop_duplicates(subset="listing_id").copy()

def compute_entire_home_stats(df: pd.DataFrame) -> dict:
    """Summary stats for entire-home listings and commercialisation proxies."""
    d = _unique_listings(df)

    total = int(d["listing_id"].nunique())
    entire = d.loc[d["is_entire_home"]].copy()
    n_entire = int(entire["listing_id"].nunique())

    share_entire = (n_entire / total) if total else np.nan

    n_commercial = int(entire["commercial_STR"].sum())
    n_hotel_like = int(entire["hotel_like_STR"].sum())

    share_commercial = (n_commercial / n_entire) if n_entire else np.nan
    share_hotel_like = (n_hotel_like / n_entire) if n_entire else np.nan

    # optional: "legal but commercial" (commercial proxy but not >90 occupied)
    n_legal_but_commercial = int(((~entire["violates_90day"]) & (entire["commercial_STR"])).sum())
    share_legal_but_commercial = (n_legal_but_commercial / n_entire) if n_entire else np.nan

    return {
        "total_listings": total,
        "n_entire": n_entire,
        "share_entire": share_entire,
        "n_commercial_entire": n_commercial,
        "share_commercial_entire": share_commercial,
        "n_hotel_like_entire": n_hotel_like,
        "share_hotel_like_entire": share_hotel_like,
        "n_legal_but_commercial_entire": n_legal_but_commercial,
        "share_legal_but_commercial_entire": share_legal_but_commercial,
    }

def host_listing_counts(df: pd.DataFrame) -> pd.Series:
    """Number of listings per host (unique listings)."""
    d = _unique_listings(df)
    return d.groupby("host_id")["listing_id"].nunique()

## 5.2 Plots
def plot_host_distribution(host_structure_stats: dict, max_listings: int = 12) -> None:
    """Figure-4: Host distribution (capped)."""
    vc = host_counts.value_counts().sort_index()
    vc = vc[vc.index <= max_listings]

    plt.figure(figsize=(8, 5))
    plt.bar(vc.index.astype(int), vc.values)
    plt.xlabel("Listings per host")
    plt.ylabel("Number of hosts")
    plt.title("Figure-4 Host Distribution (Capped)")
    plt.tight_layout()

def plot_commercial_composition(stats: dict) -> None:
    """Figure-5: Composition of commercialisation (shares among entire homes)."""
    labels = ["Commercial STR","Hotel-like STR","Legal but commercial"]
    values = [
        stats["share_commercial_entire"],
        stats["share_hotel_like_entire"],
        stats["share_legal_but_commercial_entire"],
    ]

    plt.figure(figsize=(7, 4))
    plt.bar(labels, values)
    plt.ylabel("Share of entire-home listings")
    plt.ylim(0, 1)
    plt.title("Figure-5 Commercialisation Composition (Entire Homes)")
    plt.tight_layout()
```


```{python}
#| echo: false
## 5.3 Compute Stats Only
RUN_COMMERCIAL = True
SHOW_COMM_STATS = False

if RUN_COMMERCIAL:
    comm_stats = compute_entire_home_stats(merged)
    host_counts = host_listing_counts(merged)

    if SHOW_COMM_STATS:
        print("=== Commercialisation summary (entire homes) ===")
        for k, v in comm_stats.items():
            print(f"{k}: {v:.3f}" if isinstance(v, float) else f"{k}: {v}")
```

```{python}
#| echo: false
## 5.4 Figure 4: Host distribution
SHOW_HOST_PLOT = True   

if RUN_COMMERCIAL and SHOW_HOST_PLOT:
    plot_host_distribution(host_counts, max_listings=12)
```
Figure 4 – Host size distribution: Most hosts manage one listing, but thousands operate multiple units and a notable cohort controls 10+. This indicates professional landlord activity rather than casual participation.


```{python}
## 5.5 Figure 5: Commercial composition
SHOW_COMM_COMP_PLOT = True   

if RUN_COMMERCIAL and SHOW_COMM_COMP_PLOT:
    plot_commercial_composition(comm_stats)
```
Figure 5 – Availability categories: Nearly half of entire homes show commercial or hotel-like availability, implying widespread year-round operation, consistent with patterns of housing withdrawal documented in prior studies.
```{python}
#| output: asis
print(
    f"In total, {((merged['commercial_STR'] | merged['hotel_like_STR']) & merged['is_entire_home']).mean():.0%} "
    "of entire-home listings exhibit commercial or hotel-like availability patterns."
)
```

In relation to “out of control,” these patterns show an STR sector functioning as de facto commercial accommodation, expanding beyond the level policymakers intended to regulate.


### Spatial

A third indicator of whether Airbnb is “out of control” is the spatial concentration of STR activity, as dense or clustered STR markets are strongly associated with heightened housing pressure [@doi:10.1177/0042098020970865; @Gyódi01092024]. Using borough-level listings, housing stock estimates, and spatial statistics computed in Jupyter, we identify three patterns.


```{python}
#| echo: false
#6 Spatial Join & Build Borough-level Tables 
## 6.1 Read borough polygons
boros = gpd.read_file(borough_path)
boros["borough"] = boros["NAME"].astype(str).str.strip().str.lower()

## 6.2 Point GeoDataFrame & spatial join
# Create point-level GeoDataFrame (borough polygons remain unchanged)
pts = gpd.GeoDataFrame(
    merged.copy(),
    geometry=gpd.points_from_xy(merged["longitude"], merged["latitude"]),
    crs="EPSG:4326"
).to_crs(boros.crs)

pts_boro = (
    gpd.sjoin(pts, boros[["borough", "geometry"]], how="left", predicate="within")
    .dropna(subset=["borough"])
    .copy()
)

## 6.3 Spatial Map 1: STR density per 1000 dwellings 
stock = pd.read_csv(stock_path)
dwell_col = "Number of self-contained units or bedspaces-2024"

"""housing stock (denominator)"""
housing = (
    stock
    .assign(
        borough=stock["Area"].astype(str).str.strip().str.lower(),
        dwellings=(
            stock[dwell_col]
            .astype(str)
            .str.replace(",", "", regex=False)
        )
    )
)

housing["dwellings"] = pd.to_numeric(housing["dwellings"], errors="coerce")
housing = housing[["borough", "dwellings"]]

"""STR counts (numerator)"""
borough_counts = (
    pts_boro.groupby("borough", as_index=False)
    .agg(n_listings=("listing_id", "nunique"))
)

"""density per 1,000 dwellings """
density_df = borough_counts.merge(housing, on="borough", how="left")
density_df["str_density_per_1000"] = (
    density_df["n_listings"] / density_df["dwellings"] * 1000
)

boros_density = boros.merge(
    density_df[["borough", "str_density_per_1000"]],
    on="borough",
    how="left",
)

## 6.4 Spatial Map 2: Commercial STR share
borough_comm = (
    pts_boro.groupby("borough", as_index=False)
    .agg(
        n_total=("listing_id", "nunique"),
        n_commercial=("commercial_STR", "sum"),
    )
)

borough_comm["commercial_share"] = (borough_comm["n_commercial"] / borough_comm["n_total"])

boros_comm = boros.merge(
    borough_comm[["borough", "commercial_share"]],
    on="borough",
    how="left",
)

## 6.5 plot
def plot_borough_choropleth(
    gdf: gpd.GeoDataFrame,
    column: str,
    title: str,
    cmap: str = "OrRd",
    figsize: tuple = (8, 8),
) -> None:
    ax = gdf.plot(
        column=column,
        legend=True,
        cmap=cmap,
        figsize=figsize,
        edgecolor="white",
        linewidth=0.5,
        missing_kwds={
            "color": "lightgrey",
            "label": "No data",
        },
    )
    ax.set_title(title)
    ax.set_axis_off()
    plt.tight_layout()
```

```{python}
#| echo: false
## 6.6 Spatial Map 1: STR density per 1,000 dwellings
SHOW_MAP_STR_DENSITY = True

if SHOW_MAP_STR_DENSITY:
    plot_borough_choropleth(
        boros_density,
        column="str_density_per_1000",
        title="Map-1 STR Density (Listings per 1,000 dwellings)",
        cmap="OrRd",
        figsize=(8, 8),
    )
```
Map 1– STR density: Central boroughs exhibit densities far above the rest of London, indicating intense competition for housing in areas already under market pressure.


```{python}
#| echo: false
## 6.7 Spatial Map 2: Commercial STR share by borough
SHOW_MAP_COMMERCIAL = True

if SHOW_MAP_COMMERCIAL:
    plot_borough_choropleth(
        boros_comm,
        column="commercial_share",
        title="Map-2 Commercial STR Share by Borough",
        cmap="PuRd",
        figsize=(7, 7),
    )
```
Map 2 – Commercial STR share: These same boroughs also display high proportions of commercial STRs, reinforcing their role as hotspots of investment-driven short letting rather than casual home-sharing.



```{python}
#| echo: false
#7 Spatial Autocorrelation (Global Moran + Moran scatter + Local Moran LISA map)
## 7.1 Defination & Compute
RUN_SPATIAL_STATS = True
VERBOSE_SPATIAL = False  

"""Moran's I + LISA (no esda)"""
def morans_I_global(z: np.ndarray, w) -> float:
    """Observed Global Moran's I using row-standardised weights."""
    n = len(z)
    S0 = w.s0
    Wz = w.sparse @ z
    return (n / S0) * (z @ Wz) / (z @ z)


def permute_global_I(z: np.ndarray, w, perms: int = 999, seed: int = 42) -> tuple[float, float, np.ndarray]:
    """Permutation test (two-sided) for Global Moran's I."""
    rng = np.random.default_rng(seed)
    I_obs = morans_I_global(z, w)

    I_perm = np.empty(perms, dtype=float)
    for p in range(perms):
        z_perm = rng.permutation(z)
        I_perm[p] = morans_I_global(z_perm, w)

    p_two = (np.sum(np.abs(I_perm) >= np.abs(I_obs)) + 1) / (perms + 1)
    return I_obs, p_two, I_perm


def lisa_no_esda(z: np.ndarray, w, perms: int = 999, seed: int = 42, alpha: float = 0.05) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """Local Moran-style cluster labels using permutations (no esda)."""
    """Observed local stat: Ii = z_i * (Wz)_i  (row-standardised W)"""
    """p-values computed two-sided via permutation distribution of Ii."""
    rng = np.random.default_rng(seed)

    lag_z = w.sparse @ z
    Ii_obs = z * lag_z

    # simulate: for each permutation, compute Ii_perm for all i at once
    sims = np.empty((perms, len(z)), dtype=float)
    for p in range(perms):
        z_perm = rng.permutation(z)
        sims[p, :] = z * (w.sparse @ z_perm)   # keep z_i fixed, permute neighbors globally

    # two-sided p-values
    p_local = (np.sum(np.abs(sims) >= np.abs(Ii_obs), axis=0) + 1) / (perms + 1)

    # quadrant-based cluster labels (significant only)
    cluster = np.full(len(z), "Not significant", dtype=object)
    sig = p_local <= alpha

    cluster[sig & (z > 0) & (lag_z > 0)] = "High-High"
    cluster[sig & (z < 0) & (lag_z < 0)] = "Low-Low"
    cluster[sig & (z > 0) & (lag_z < 0)] = "High-Low"
    cluster[sig & (z < 0) & (lag_z > 0)] = "Low-High"

    return lag_z, p_local, cluster

"""prepare gdf and z"""
gdf = (
    boros_density[["geometry", "str_density_per_1000"]]
    .dropna(subset=["str_density_per_1000"])
    .reset_index(drop=True)
)

y = gdf["str_density_per_1000"].to_numpy(float)
z = (y - y.mean()) / y.std(ddof=1)  # z-score

# weights
w = Queen.from_dataframe(gdf, use_index=False)
w.transform = "R"

# Global Moran
if RUN_SPATIAL_STATS:
    I_obs, p_two, I_perm = permute_global_I(z, w, perms=999, seed=42)

    vprint(
        VERBOSE_SPATIAL,
        f"Global Moran's I: {I_obs:.4f} "
        f"(two-sided p={p_two:.4f}, 999 permutations)"
    )

# Local (LISA-style)
if RUN_SPATIAL_STATS:
    alpha = 0.05
    lag_z, p_local, cluster = lisa_no_esda(
        z, w, perms=999, seed=42, alpha=alpha
    )

    gdf_lisa = gdf.copy()
    gdf_lisa["z"] = z
    gdf_lisa["lag_z"] = lag_z
    gdf_lisa["p"] = p_local
    gdf_lisa["cluster"] = cluster

    vprint(
        VERBOSE_SPATIAL,
        gdf_lisa["cluster"].value_counts()
    )
```

```{python}
#| echo: false
## 7.2 Global Moran's I: Moran scatterplot
SHOW_MORAN_SCATTER = False

# Moran scatterplot
if SHOW_MORAN_SCATTER:
    plt.figure(figsize=(6, 6))
    plt.scatter(z, lag_z, s=25)
    plt.axhline(0, linewidth=1)
    plt.axvline(0, linewidth=1)

    slope = np.polyfit(z, lag_z, 1)[0]  # slope ≈ Moran's I
    xs = np.array([z.min(), z.max()])
    plt.plot(xs, slope * xs)

    plt.xlabel("Standardised STR density (z)")
    plt.ylabel("Spatial lag (Wz)")
    plt.title(f"Moran scatterplot (slope≈I={I_obs:.3f})")
    plt.tight_layout()
```

```{python}
#| echo: false
## 7.3 Local Moran's I: LISA Cluster Map
SHOW_LISA_MAP = True

if SHOW_LISA_MAP:
    lisa_colors = {
    "High-High": "#d7191c",
    "Low-Low": "#2c7bb6",
    "High-Low": "#fdae61",
    "Low-High": "#abd9e9",
    "Not significant": "#d9d9d9",
    }

    ax = gdf_lisa.plot(
    color=gdf_lisa["cluster"].map(lisa_colors),
    edgecolor="white",
    linewidth=0.8,
    figsize=(8, 8),
    )

    ax.set_title(f"Map-3 Local Moran's I (LISA) clusters for STR density (p ≤ {alpha})")
    ax.set_axis_off()

    handles = [
    mpatches.Patch(color=lisa_colors[k], label=k)
    for k in ["High-High", "Low-Low", "High-Low", "Low-High", "Not significant"]
]
ax.legend(handles=handles, title="LISA cluster type", loc="upper right")

plt.tight_layout()
```
Map 3– LISA clustering: Local Moran’s I reveals a significant High–High cluster in the city centre, showing that STR pressures are spatially reinforcing rather than randomly distributed.

In relation to “out of control,” the spatial evidence suggests that STR activity concentrates in sensitive housing markets, amplifying displacement risks and exceeding the city’s capacity to manage its geographic impacts.

### In Conclusion

Across regulatory, commercial, and spatial dimensions, London’s STR activity consistently exceeds intended limits, with widespread rule violations, professionalised hosting, and concentrated hotspots—together suggesting that Airbnb activity in London exceeds the level of control originally intended by policymakers.Whether Airbnb is considered “out of control” ultimately depends on how strictly one interprets the 90-day rule and what level of commercial activity is deemed acceptable.

{{< pagebreak >}}

# Q2. How many professional landlords are there?

To accurately assess the potential impact of the opposition's proposal, this analysis first established a rigorous quantitative standard to distinguish between "sharing economy participants" and "commercial operators." Drawing on research by [@wachsmuth2018rentgap] regarding the structure of short-term rental markets, relying solely on the number of listings is insufficient to fully define commercial attributes; therefore, listing type and activity levels must be integrated into the assessment. Consequently, we formulated the following logic to define a "Professional Landlord" within the data processing workflow: the host must meet a dual threshold of "Operational Scale" and "Activity Level." In terms of scale, the definition includes hosts owning 3 or more listings of any type, or 2 or more "entire home" listings. This distinction is based on the premise that hosts with multiple entire homes cannot simultaneously inhabit these properties, rendering their activity "necessarily commercial" rather than residential sharing.Regarding activity level, we excluded inactive accounts by including only those with an annual availability exceeding 90 days. Availability over 90 days is used here as a conservative proxy for sustained short-term letting activity, recognising that it does not directly measure realised bookings. As noted by [@gurran2017airbnb], high-frequency short-term letting (e.g., exceeding 90 days) is a critical indicator for determining whether housing has been removed from the permanent rental market, thereby causing neighborhood disruption.

```{python}
#| echo: false
## 8 Select professional landlords
SHOW_RESULTS = False
listings = pd.read_csv(listings_path)
if SHOW_RESULTS:
    print("Listings:", listings.shape)

cols = [
    "id", "host_id", "room_type",
    "availability_365", "neighbourhood_cleansed",
    "latitude", "longitude"
]

df = listings[cols].copy()    
if SHOW_RESULTS:
    print("Columns loaded:", df.columns)
```

```{python}
#| echo: False
## 9 calculate professional landlords
SHOW_RESULTS = False
host_stats = df.groupby("host_id").agg(
    total_listings = ('id','count'),
    entire_homes   = ('room_type', lambda x: (x=="Entire home/apt").sum()),
    avail_over_90  = ('availability_365', lambda x: (x>90).sum())
).reset_index()

host_stats["is_PL"] = (
    ((host_stats.total_listings >= 3) | (host_stats.entire_homes >= 2))
    & (host_stats.avail_over_90 > 0)
)

final_hosts = host_stats[host_stats.is_PL].host_id.unique()

Q2 = len(final_hosts)
if SHOW_RESULTS:
    print("Q2 Number of professional landlords =", Q2)
```

Based on these definitions, we utilized Python to conduct systematic cleaning and mining of the London Airbnb dataset. The analysis process first aggregated the full listing data by Host ID (`host_id`), calculating the total number of listings and the specific count of "entire home" listings for each host. Subsequently, using boolean indexing combined with calendar availability data (`availability_365`), we filtered for samples that simultaneously met the "multiple listing holding" and "high-frequency rental (>90 days)" criteria.This algorithmic logic ensured that the identified subjects precisely corresponded to the "commercial operators" targeted by the opposition's proposal, effectively excluding ordinary citizens occasionally renting out their primary residences.This definition reflects a policy-oriented interpretation of “professional landlords”, prioritising scale and sustained market presence over formal ownership structures.

```{python}
#| echo: false
## 10 Calculate host's listing and proportion
SHOW_RESULTS = False
df["is_PL_listing"] = df["host_id"].isin(final_hosts)
Q31 = df["is_PL_listing"].sum()
if SHOW_RESULTS:
    print("Q3.1 Number of Properties Owned by Professional Landlords =", Q31)

total_listings = len(df)
Q32 = Q31 / total_listings
if SHOW_RESULTS:
    print("Q3.2 Proportion of properties listed by professional landlords =", round(Q32,4))
```
Through the algorithmic filtering described above, we identified 5,345 professional landlords currently operating in London. Although this figure may appear limited relative to the total base of hosts, it exhibits significant clustering characteristics.The distribution analysis reveals a distinct "long tail" effect, where a segment of top-tier operators manages large-scale portfolios. This finding validates the observations of [@deboosere2019airbnb], who note that the short-term rental market is undergoing a rapid process of "professionalization," wherein a minority of commercial entities capture excess returns through scaled management, thereby intensifying competition with the traditional housing market.

```{python}
#| echo: false
## 11 Map distribution of multi-listing hosts
PL_hosts = host_stats[host_stats.is_PL]
non_PL_hosts = host_stats[~host_stats.is_PL]

PL_plot = PL_hosts[PL_hosts.total_listings > 1]
non_PL_plot = non_PL_hosts[non_PL_hosts.total_listings > 1]

plt.figure(figsize=(8,5))

plt.hist(
    PL_plot["total_listings"],
    bins=range(2, 40),
    alpha=0.7,
    label="Professional landlords"
)

plt.hist(
    non_PL_plot["total_listings"],
    bins=range(2, 40),
    alpha=0.7,
    label="Non-professional landlords"
)

plt.xlim(2, 40)
plt.xlabel("Number of listings per host (>1)")
plt.ylabel("Number of hosts")
plt.title("Figure-6 Distribution of multi-listing hosts")
plt.legend()
```
Figure 6-Distribution of Multi-Listing Hosts: The histogram visualizes the distribution of hosts with multiple listings, distinguishing between professional and non-professional operators. It reveals a stark contrast in operational scale: while non-professional hosts are overwhelmingly concentrated at the lower threshold (typically owning just two properties), the professional segment exhibits a distinct "long tail." This demonstrates that professional landlords are characterized by the management of extensive property portfolios, extending well beyond the activity patterns of casual home-sharers.

```{python}
#| echo: false
## 12 Plot professional landlord listings on the map
# Generate point data + spatial join
#| warning: false
#| message: false
warnings.filterwarnings("ignore", category=FutureWarning)

if "is_PL" not in merged.columns:
    merged = merged.merge(
        host_stats[["host_id", "is_PL"]],
        on="host_id",
        how="left"
    )
    merged["is_PL"] = merged["is_PL"].fillna(False)

pts = gpd.GeoDataFrame(
    merged.copy(),
    geometry=gpd.points_from_xy(merged["longitude"], merged["latitude"]),
    crs="EPSG:4326"
).to_crs(boros.crs)

pts_boro = gpd.sjoin(
    pts,
    boros[["borough", "geometry"]],
    how="left",
    predicate="within"
)

pl_pts = pts_boro[pts_boro["is_PL"] == True].copy()

# Plot the map
import matplotlib.pyplot as plt

fig, ax = plt.subplots(1, 1, figsize=(8, 8))

# Borough boundaries
boros.plot(
    ax=ax,
    color="white",
    edgecolor="black",
    linewidth=0.5
)

# Professional landlord listings
pl_pts.plot(
    ax=ax,
    color="red",
    markersize=1,
    alpha=0.4
)

ax.set_title("Map-4 Spatial distribution of professional landlord listings in London")
ax.axis("off")

# ---- Scale bar ----
xmin, ymin, xmax, ymax = boros.total_bounds
scale_length = 5000  # 5 km

x_start = xmin + 0.05 * (xmax - xmin)
y_start = ymin + 0.05 * (ymax - ymin)

ax.plot(
    [x_start, x_start + scale_length],
    [y_start, y_start],
    color="black",
    linewidth=3
)

ax.text(
    x_start + scale_length / 2,
    y_start + 0.01 * (ymax - ymin),
    "5 km",
    ha="center",
    va="bottom",
    fontsize=10
)

# ---- North arrow ----
arrow_x = xmin + 0.90 * (xmax - xmin)
arrow_y = ymin + 0.15 * (ymax - ymin)

ax.annotate(
    'N',
    xy=(arrow_x, arrow_y + 3000),
    xytext=(arrow_x, arrow_y),
    arrowprops=dict(facecolor='black', width=4, headwidth=12),
    ha='center',
    va='center',
    fontsize=12,
    fontweight='bold'
)
plt.show()
```
Map4-Spatial Distribution of Professional Landlord Listings: This figure displays the spatial distribution of Airbnb listings managed by professional landlords across the Greater London area. The map reveals a stark "core–periphery" pattern, where the vast majority of commercial listings are densely clustered within Central London boroughs. Conversely, the outer boroughs show a significantly more sparse and scattered distribution of these professional listings.This geographic disparity highlights that high-intensity professional hosting is primarily a central-city phenomenon rather than a uniform issue across the capital.


{{< pagebreak >}}

# Q3. How many properties would be affected by the opposition’s proposal?

The actual penetration of the opposition's proposal is more starkly reflected in the property-level statistics. 

First, these 5,345 professional landlords collectively hold 37,609 properties. (‘properties’ refer to active Airbnb listings, which are treated as a proxy for individual housing units.)This implies that if the opposition's registration and tax hike plan were implemented, it would directly affect this magnitude of housing stock. These properties are predominantly high-frequency "entire home" rentals; as indicated by [@lee2016airbnb] and supported by [@gurran2017airbnb], the large-scale conversion of such units often corresponds directly to the loss of stock in the long-term rental market, acting as a structural factor in housing supply constraints.

Second, in terms of market share, these 37,609 properties account for 38.91% of all active Airbnb listings in London. This proportion holds high policy significance: although professional landlords comprise only around five thousand individuals, they control nearly 40% of the market supply. This aligns with the "Rent Gap" theory proposed by [@wachsmuth2018rentgap], which suggests that capital acutely captures the excess profit of short-term rentals over long-term leases, driving the transfer of housing inventory toward high-intensity commercial use. The fact that nearly 40% of the market is controlled by this group provides a strong evidential basis for claims that Airbnb activity in London exceeds its original regulatory intent.

In conclusion, while the opposition's proposal targets a minority of individuals (approximately 5,300), its policy impact would cover a core segment of the market (approximately 39% of listings). Should the Mayor choose to adopt this proposal, these data points support a narrative of "precision targeting": effectively curbing the erosion of the housing market by large-scale commercial operations while protecting the occasional sharing activities of the majority of ordinary citizens.



{{< pagebreak >}}

# Q4. What are the likely pros and cons of the opposition’s proposal (for the Mayor, for residents, and for the city)?

The opposition’s proposal to require registration and impose higher council tax on professional landlords would have uneven impacts across stakeholders. Drawing on the preceding analysis, its effects can be assessed from the perspectives of the Mayor, residents, and the city as a whole.

### The Mayor’s perspective

From the Mayor’s standpoint, the proposal offers a politically and administratively targeted intervention. Evidence from Q1 and Q2 shows that a relatively small group of professional hosts—around 5,300 individuals—controls nearly 40% of Airbnb listings, many of which operate at commercial intensity and frequently breach the 90-day rule. Targeting this group allows the Mayor to demonstrate decisive action on housing without penalising the majority of casual hosts. Increased registration and taxation would also improve transparency and enforcement capacity, addressing the regulatory failures identified in Part 1.

However, the policy carries risks. It may provoke resistance from property owners and the short-term rental industry, and enforcement costs could be politically sensitive if revenues do not clearly offset them.

### Residents’ perspective

For residents, particularly long-term renters, the proposal has clear potential benefits. Q1 and Q3 indicate that commercial short-term rentals disproportionately involve entire homes with high availability and occupancy, effectively removing housing from the long-term rental market. By discouraging large-scale commercial operation, the proposal could help return some housing stock to residential use, easing pressure on rents and neighbourhood stability.
Conversely, residents who rely on Airbnb income as supplementary earnings may perceive the policy as unfair if implementation is poorly differentiated, highlighting the importance of accurately distinguishing professional operators from casual sharers.

### The city-wide perspective

At the city scale, the proposal aligns with broader housing and planning objectives. The strong concentration of market share and revenue among professional hosts, combined with widespread non-compliance with existing regulations, suggests that unchecked commercialisation risks undermining housing supply and urban governance. Registration and higher taxation could internalise some of these externalities while generating public revenue.

Nonetheless, there is a potential downside if overly restrictive measures reduce tourism capacity or push activity into less transparent, informal markets.

Overall, the proposal’s main strength lies in its ability to precisely target a highly commercialised sub-market, balancing housing protection with continued support for genuine home-sharing.

{{< pagebreak >}}

# Q5. Can the story be reframed as a positive one about social mobility or housing opportunity?

Accepting the opposition’s proposal allows the Mayor to reframe the Airbnb debate away from moral panic or platform-level blame, and toward a positive narrative centred on housing opportunity, fairness, and social mobility. The analysis in Q1 demonstrates that London’s short-term rental market is not simply large, but structurally misaligned with its regulatory intent. Widespread breaches of the 90-day rule and weak enforcement show that existing safeguards have failed to prevent the conversion of residential housing into de facto commercial accommodation. Q2 and Q3 further reveal that this is not driven by ordinary residents, but by a relatively small group of professional landlords who operate entire homes at scale and control a disproportionate share of supply. Against this background, accepting the proposal can be framed as an intervention to restore access to housing opportunity. By increasing the costs faced by large-scale commercial operators, the policy directly targets those most responsible for removing homes from the long-term rental market. This creates the conditions for housing to flow back toward residential use, benefiting long-term renters and stabilising neighbourhoods without undermining genuine home-sharing.

From a social mobility perspective, the distinction matters. Casual hosting can provide supplementary income and resilience for households under financial pressure, supporting upward mobility. Unchecked commercialisation, by contrast, concentrates housing assets and income among a small group while reducing access for others. The proposal therefore supports mobility by protecting the former while constraining the latter. Accepting the proposal enables the Mayor to present regulation not as opposition to innovation, but as fair governance of housing as a shared urban resource—one that balances opportunity, affordability, and community stability across the city.

{{< pagebreak >}}

## References
